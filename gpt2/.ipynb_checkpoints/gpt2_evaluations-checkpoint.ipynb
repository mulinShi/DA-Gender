{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"eval_utils\")\n",
    "\n",
    "from eval_utils.evaluating_over_debiasing_gpt2 import add_predicts, get_vios_and_dif\n",
    "from eval_utils.seat_v1 import get_embeddings, compute_effect_size\n",
    "from eval_utils.seat_v2_and_logprob import convert_tmps_to_sents, comput_asso_for_autoregressive, add_assos\n",
    "from eval_utils.bias_utils.debiasing_effects_util import get_effect_size\n",
    "\n",
    "eval_type = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before Debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load tmps from data/simple_patterns\n",
      "--- 1136 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "Loading the model and the tokenizer from gpt2 \n",
      "****** need_reload :  True\n",
      "****** Need to reload...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1136/1136 [00:15<00:00, 71.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For SEAT: effect size is 0.7465725130985419, p value is 0.1537\n"
     ]
    }
   ],
   "source": [
    "tmp_path = 'data/simple_patterns'\n",
    "\n",
    "corpus, tmps_type, temp_size = convert_tmps_to_sents('data/simple_patterns', eval_type = eval_type\\\n",
    "                                                 , simple = True)\n",
    "corpus, sent2emb = comput_asso_for_autoregressive(corpus, tmps_type, temp_size, model_type = 'gpt2')\n",
    "\n",
    "seat_effect_size, seat_p = get_effect_size(corpus)\n",
    "print(\"For SEAT: effect size is {}, p value is {}\".format(seat_effect_size, seat_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 234 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "Loading the model and the tokenizer from gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/234 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** need_reload :  True\n",
      "****** Need to reload...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 234/234 [00:03<00:00, 76.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For standard SEAT: effect size is 0.28515287289385016, p value is 0.22406\n"
     ]
    }
   ],
   "source": [
    "if eval_type == 'val':\n",
    "    ori_seat_corpus_path = 'data/val_new_ori_seat_data.json'\n",
    "elif eval_type == 'test':\n",
    "    ori_seat_corpus_path = 'data/test_new_ori_seat_data.json'\n",
    "else:\n",
    "    assert eval_type == 'whole'\n",
    "    ori_seat_corpus_path = 'data/new_ori_seat_data.json'\n",
    "\n",
    "with open(ori_seat_corpus_path, 'r') as f:\n",
    "    test = json.load(f)\n",
    "\n",
    "sent2emb = get_embeddings(test, model_type = 'gpt2')\n",
    "\n",
    "seat_ez, p = compute_effect_size(test, sent2emb = sent2emb)\n",
    "\n",
    "print(\"For standard SEAT: effect size is {}, p value is {}\".format(seat_ez, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model and the tokenizer from gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2610/2610 [01:11<00:00, 36.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On UAL_Gender\n",
      "{'error_num': 609, 'error_rate': 0.23333333333333334, 'IA': 0.0014952398788587473}\n"
     ]
    }
   ],
   "source": [
    "data_without_preds_path = 'data/2610_sents_for_evaluating_gender_loss.tsv'\n",
    "\n",
    "data_without_preds = pd.read_csv(data_without_preds_path, sep='\\t', index_col = 0)\n",
    "\n",
    "data = add_predicts(data_without_preds, model_type = 'gpt2')\n",
    "violates, difs = get_vios_and_dif(data)\n",
    "\n",
    "over_debias = {}\n",
    "\n",
    "error_num = len(violates)\n",
    "over_debias['error_num'] = error_num\n",
    "\n",
    "error_rate = len(violates)/len(data)\n",
    "over_debias['error_rate'] = error_rate\n",
    "\n",
    "IA = sum(difs) / len(difs)\n",
    "over_debias['IA'] = IA\n",
    "\n",
    "print(\"On UAL_Gender\")\n",
    "print(over_debias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Sent_debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load tmps from data/simple_patterns\n",
      "* load gender dir from  debias_methods/saved_models/sent_debias/base_sent/gender_dir_1.0\n",
      "--- 1136 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "Loading the model and the tokenizer from gpt2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/1136 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** need_reload :  True\n",
      "****** Need to reload...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1136/1136 [00:16<00:00, 70.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debiasing by sent_debias...\n",
      "For SEAT: effect size is 0.023375177096949824, p value is 0.96303\n"
     ]
    }
   ],
   "source": [
    "tmp_path = 'data/simple_patterns'\n",
    "\n",
    "corpus, tmps_type, temp_size = convert_tmps_to_sents('data/simple_patterns',\\\n",
    "                                                 eval_type = eval_type, simple = True)\n",
    "corpus, sent2emb = comput_asso_for_autoregressive(corpus, tmps_type, temp_size, model_type = 'gpt2'\\\n",
    "                                                 , subspace_path = 'debias_methods/saved_models/sent_debias/base_sent/gender_dir_1.0')\n",
    "\n",
    "seat_effect_size, seat_p = get_effect_size(corpus)\n",
    "print(\"For SEAT: effect size is {}, p value is {}\".format(seat_effect_size, seat_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* load gender dir from  debias_methods/saved_models/sent_debias/base_sent/gender_dir_1.0\n",
      "--- 234 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "Loading the model and the tokenizer from gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/234 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** need_reload :  True\n",
      "****** Need to reload...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 234/234 [00:03<00:00, 75.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debiasing by sent_debias...\n",
      "For standard SEAT: effect size is -0.026900173228359987, p value is 0.90948\n"
     ]
    }
   ],
   "source": [
    "if eval_type == 'val':\n",
    "    ori_seat_corpus_path = 'data/val_new_ori_seat_data.json'\n",
    "elif eval_type == 'test':\n",
    "    ori_seat_corpus_path = 'data/test_new_ori_seat_data.json'\n",
    "else:\n",
    "    assert eval_type == 'whole'\n",
    "    ori_seat_corpus_path = 'data/new_ori_seat_data.json'\n",
    "\n",
    "with open(ori_seat_corpus_path, 'r') as f:\n",
    "    test = json.load(f)\n",
    "\n",
    "sent2emb = get_embeddings(test, model_type = 'gpt2'\\\n",
    "                                                 , subspace_path = 'debias_methods/saved_models/sent_debias/base_sent/gender_dir_1.0')\n",
    "\n",
    "seat_ez, p = compute_effect_size(test, sent2emb = sent2emb)\n",
    "\n",
    "print(\"For standard SEAT: effect size is {}, p value is {}\".format(seat_ez, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* load gender dir from  debias_methods/saved_models/sent_debias/base_sent/gender_dir_1.0\n",
      "Loading the model and the tokenizer from gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2610/2610 [01:23<00:00, 31.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On UAL_Gender\n",
      "{'error_num': 1934, 'error_rate': 0.7409961685823755, 'IA': -5.773676530009415e-08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_without_preds_path = 'data/2610_sents_for_evaluating_gender_loss.tsv'\n",
    "\n",
    "data_without_preds = pd.read_csv(data_without_preds_path, sep='\\t', index_col = 0)\n",
    "\n",
    "data = add_predicts(data_without_preds, model_type = 'gpt2'\\\n",
    "                                                 , subspace_path = 'debias_methods/saved_models/sent_debias/base_sent/gender_dir_1.0')\n",
    "violates, difs = get_vios_and_dif(data)\n",
    "\n",
    "over_debias = {}\n",
    "\n",
    "error_num = len(violates)\n",
    "over_debias['error_num'] = error_num\n",
    "\n",
    "error_rate = len(violates)/len(data)\n",
    "over_debias['error_rate'] = error_rate\n",
    "\n",
    "IA = sum(difs) / len(difs)\n",
    "over_debias['IA'] = IA\n",
    "\n",
    "print(\"On UAL_Gender\")\n",
    "print(over_debias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT_2_MEDIUM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before Debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load tmps from data/simple_patterns\n",
      "--- 1136 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "Loading the model and the tokenizer from gpt2-medium \n",
      "****** need_reload :  True\n",
      "****** Need to reload...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1136/1136 [00:27<00:00, 40.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For SEAT: effect size is -0.2981796581707961, p value is 0.57328\n"
     ]
    }
   ],
   "source": [
    "tmp_path = 'data/simple_patterns'\n",
    "\n",
    "corpus, tmps_type, temp_size = convert_tmps_to_sents('data/simple_patterns', eval_type = eval_type,\\\n",
    "                                                 simple = True)\n",
    "corpus, sent2emb = comput_asso_for_autoregressive(corpus, tmps_type, temp_size, model_type = 'gpt2-medium')\n",
    "\n",
    "seat_effect_size, seat_p = get_effect_size(corpus)\n",
    "print(\"For SEAT: effect size is {}, p value is {}\".format(seat_effect_size, seat_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 234 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "Loading the model and the tokenizer from gpt2-medium\n",
      "****** need_reload :  True\n",
      "****** Need to reload...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 234/234 [00:05<00:00, 41.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For standard SEAT: effect size is -0.3297822561549808, p value is 0.1591\n"
     ]
    }
   ],
   "source": [
    "if eval_type == 'val':\n",
    "    ori_seat_corpus_path = 'data/val_new_ori_seat_data.json'\n",
    "elif eval_type == 'test':\n",
    "    ori_seat_corpus_path = 'data/test_new_ori_seat_data.json'\n",
    "else:\n",
    "    assert eval_type == 'whole'\n",
    "    ori_seat_corpus_path = 'data/new_ori_seat_data.json'\n",
    "\n",
    "with open(ori_seat_corpus_path, 'r') as f:\n",
    "    test = json.load(f)\n",
    "\n",
    "sent2emb = get_embeddings(test, model_type = 'gpt2-medium')\n",
    "\n",
    "seat_ez, p = compute_effect_size(test, sent2emb = sent2emb)\n",
    "\n",
    "print(\"For standard SEAT: effect size is {}, p value is {}\".format(seat_ez, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model and the tokenizer from gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2610/2610 [02:24<00:00, 18.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On UAL_Gender\n",
      "{'error_num': 413, 'error_rate': 0.1582375478927203, 'IA': 0.002433732236244269}\n"
     ]
    }
   ],
   "source": [
    "data_without_preds_path = 'data/2610_sents_for_evaluating_gender_loss.tsv'\n",
    "\n",
    "data_without_preds = pd.read_csv(data_without_preds_path, sep='\\t', index_col = 0)\n",
    "\n",
    "data = add_predicts(data_without_preds, model_type = 'gpt2-medium')\n",
    "violates, difs = get_vios_and_dif(data)\n",
    "\n",
    "over_debias = {}\n",
    "\n",
    "error_num = len(violates)\n",
    "over_debias['error_num'] = error_num\n",
    "\n",
    "error_rate = len(violates)/len(data)\n",
    "over_debias['error_rate'] = error_rate\n",
    "\n",
    "IA = sum(difs) / len(difs)\n",
    "over_debias['IA'] = IA\n",
    "\n",
    "print(\"On UAL_Gender\")\n",
    "print(over_debias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Sent_debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load tmps from data/simple_patterns\n",
      "* load gender dir from  debias_methods/saved_models/sent_debias/large_sent/gender_dir_1.0\n",
      "--- 1136 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "Loading the model and the tokenizer from gpt2-medium \n",
      "****** need_reload :  True\n",
      "****** Need to reload...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1136/1136 [00:29<00:00, 38.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debiasing by sent_debias...\n",
      "For SEAT: effect size is 0.011585961206264062, p value is 0.98524\n"
     ]
    }
   ],
   "source": [
    "tmp_path = 'data/simple_patterns'\n",
    "\n",
    "corpus, tmps_type, temp_size = convert_tmps_to_sents('data/simple_patterns', eval_type = eval_type,\\\n",
    "                                                 simple = True)\n",
    "corpus, sent2emb = comput_asso_for_autoregressive(corpus, tmps_type, temp_size, model_type = 'gpt2-medium'\\\n",
    "                                                 , subspace_path = 'debias_methods/saved_models/sent_debias/large_sent/gender_dir_1.0')\n",
    "\n",
    "seat_effect_size, seat_p = get_effect_size(corpus)\n",
    "print(\"For SEAT: effect size is {}, p value is {}\".format(seat_effect_size, seat_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* load gender dir from  debias_methods/saved_models/sent_debias/large_sent/gender_dir_1.0\n",
      "--- 234 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "Loading the model and the tokenizer from gpt2-medium\n",
      "****** need_reload :  True\n",
      "****** Need to reload...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 234/234 [00:06<00:00, 38.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debiasing by sent_debias...\n",
      "For standard SEAT: effect size is -0.07583661983308462, p value is 0.74745\n"
     ]
    }
   ],
   "source": [
    "if eval_type == 'val':\n",
    "    ori_seat_corpus_path = 'data/val_new_ori_seat_data.json'\n",
    "elif eval_type == 'test':\n",
    "    ori_seat_corpus_path = 'data/test_new_ori_seat_data.json'\n",
    "else:\n",
    "    assert eval_type == 'whole'\n",
    "    ori_seat_corpus_path = 'data/new_ori_seat_data.json'\n",
    "\n",
    "with open(ori_seat_corpus_path, 'r') as f:\n",
    "    test = json.load(f)\n",
    "\n",
    "sent2emb = get_embeddings(test, model_type = 'gpt2-medium'\\\n",
    "                                                 , subspace_path = 'debias_methods/saved_models/sent_debias/large_sent/gender_dir_1.0')\n",
    "\n",
    "seat_ez, p = compute_effect_size(test, sent2emb = sent2emb)\n",
    "\n",
    "print(\"For standard SEAT: effect size is {}, p value is {}\".format(seat_ez, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* load gender dir from  debias_methods/saved_models/sent_debias/large_sent/gender_dir_1.0\n",
      "Loading the model and the tokenizer from gpt2-medium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2610/2610 [02:31<00:00, 17.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On UAL_Gender\n",
      "{'error_num': 739, 'error_rate': 0.28314176245210726, 'IA': 9.054299421669588e-08}\n"
     ]
    }
   ],
   "source": [
    "data_without_preds_path = 'data/2610_sents_for_evaluating_gender_loss.tsv'\n",
    "\n",
    "data_without_preds = pd.read_csv(data_without_preds_path, sep='\\t', index_col = 0)\n",
    "\n",
    "data = add_predicts(data_without_preds, model_type = 'gpt2-medium'\\\n",
    "                                                 , subspace_path = 'debias_methods/saved_models/sent_debias/large_sent/gender_dir_1.0')\n",
    "violates, difs = get_vios_and_dif(data)\n",
    "\n",
    "over_debias = {}\n",
    "\n",
    "error_num = len(violates)\n",
    "over_debias['error_num'] = error_num\n",
    "\n",
    "error_rate = len(violates)/len(data)\n",
    "over_debias['error_rate'] = error_rate\n",
    "\n",
    "IA = sum(difs) / len(difs)\n",
    "over_debias['IA'] = IA\n",
    "\n",
    "print(\"On UAL_Gender\")\n",
    "print(over_debias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
