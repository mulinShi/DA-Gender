{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"eval_utils\")\n",
    "\n",
    "from eval_utils.evaluating_over_debiasing_bart import add_predicts_bart, get_vios_and_dif\n",
    "from eval_utils.seat_v2_and_logprob import convert_tmps_to_sents, get_embeddings_and_probs_bart, add_assos\n",
    "from eval_utils.bias_utils.debiasing_effects_util import get_effect_size\n",
    "from eval_utils.seat_v1 import get_embeddings, compute_effect_size\n",
    "\n",
    "eval_type = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BART_BASE_UNCASED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before Debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load tmps from ../data/simple_patterns\n",
      "--- 879 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "Loading tokenizer and model from facebook/bart-base\n",
      "max_len evaluation: 128\n",
      "--- get embeddings from TM and TAM---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/543 [00:00<?, ?it/s]intial_eval_utils\\bias_utils\\utils_for_diverse_tmps.py:181: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:882.)\n",
      "  mask_index = (sents[sent_id] == tokenizer.mask_token_id).nonzero().flatten().tolist()[masked_id]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 543/543 [00:25<00:00, 21.59it/s]\n",
      "  1%|▋                                                                                 | 3/336 [00:00<00:11, 28.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- get embeddings from AM---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 336/336 [00:11<00:00, 28.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For SEAT: effect size is 1.404318728528581, p value is 0.0013\n",
      "For log probability score: effect size is 1.6505342458710899, p value is 0.00027\n"
     ]
    }
   ],
   "source": [
    "tmp_path = '../data/simple_patterns'\n",
    "\n",
    "corpus, tmps_type, temp_size = convert_tmps_to_sents(tmp_path, eval_type,\\\n",
    "                                                 simple = True)\n",
    "sent2emb = get_embeddings_and_probs_bart(corpus, tmps_type, temp_size, model_type = 'facebook/bart-base')\n",
    "corpus = add_assos(corpus, tmps_type, temp_size, sent2emb = sent2emb)\n",
    "\n",
    "seat_effect_size, seat_p, log_effect_size, log_p = get_effect_size(corpus)\n",
    "print(\"For SEAT: effect size is {}, p value is {}\".format(seat_effect_size, seat_p))\n",
    "print(\"For log probability score: effect size is {}, p value is {}\".format(log_effect_size, log_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 234 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "Testing\n",
      "--- get embeddings from AM---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 234/234 [00:08<00:00, 28.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For standard SEAT: effect size is 0.4276836186717399, p value is 0.06695\n"
     ]
    }
   ],
   "source": [
    "if eval_type == 'val':\n",
    "    ori_seat_corpus_path = '../data/val_new_ori_seat_data.json'\n",
    "elif eval_type == 'test':\n",
    "    ori_seat_corpus_path = '../data/test_new_ori_seat_data.json'\n",
    "else:\n",
    "    assert eval_type == 'whole'\n",
    "    ori_seat_corpus_path = '../data/new_ori_seat_data.json'\n",
    "\n",
    "with open(ori_seat_corpus_path, 'r') as f:\n",
    "    test = json.load(f)\n",
    "\n",
    "sent2emb = get_embeddings(test, model_type = 'facebook/bart-base')\n",
    "\n",
    "seat_ez, p = compute_effect_size(test, sent2emb = sent2emb)\n",
    "\n",
    "print(\"For standard SEAT: effect size is {}, p value is {}\".format(seat_ez, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5220 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "Loading the tokenizer and the model from facebook/bart-base\n",
      "max_len evaluation: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2610/2610 [04:00<00:00, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On UAL_Gender\n",
      "{'error_num': 460, 'error_rate': 0.17624521072796934, 'IA': 1.3404051933804004}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_without_preds_path = '../data/bart_2610_sents_for_evaluating_gender_loss.tsv'\n",
    "\n",
    "data_without_preds = pd.read_csv(data_without_preds_path, sep='\\t', index_col = 0)\n",
    "\n",
    "data = add_predicts_bart(data_without_preds, model_type = \"facebook/bart-base\", subspace_path = None)\n",
    "\n",
    "violates, difs = get_vios_and_dif(data)\n",
    "\n",
    "over_debias = {}\n",
    "\n",
    "error_num = len(violates)\n",
    "over_debias['error_num'] = error_num\n",
    "\n",
    "error_rate = len(violates)/len(data)\n",
    "over_debias['error_rate'] = error_rate\n",
    "\n",
    "IA = sum(difs) / len(difs)\n",
    "over_debias['IA'] = IA\n",
    "\n",
    "print(\"On UAL_Gender\")\n",
    "print(over_debias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Sent_debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_path = '../data/simple_patterns'\n",
    "\n",
    "corpus, tmps_type, temp_size = convert_tmps_to_sents(tmp_path, eval_type,\\\n",
    "                                                 simple = True)\n",
    "sent2emb = get_embeddings_and_probs_bart(corpus, tmps_type, temp_size, model_type = 'facebook/bart-base'\\\n",
    "                                         , subspace_path = 'bart_saved_embeddings/base_sent/gender_dir_0.07')\n",
    "corpus = add_assos(corpus, tmps_type, temp_size, sent2emb = sent2emb)\n",
    "\n",
    "seat_effect_size, seat_p, log_effect_size, log_p = get_effect_size(corpus)\n",
    "print(\"For SEAT: effect size is {}, p value is {}\".format(seat_effect_size, seat_p))\n",
    "print(\"For log probability score: effect size is {}, p value is {}\".format(log_effect_size, log_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load tmps from ../data/simple_patterns\n",
      "* load gender dir from  bart_saved_embeddings/base_sent/gender_dir_0.07\n",
      "--- 879 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "Loading tokenizer and model from facebook/bart-base\n",
      "max_len evaluation: 128\n",
      "--- get embeddings from TM and TAM---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/543 [00:00<?, ?it/s]intial_eval_utils\\bias_utils\\utils_for_diverse_tmps.py:181: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:882.)\n",
      "  mask_index = (sents[sent_id] == tokenizer.mask_token_id).nonzero().flatten().tolist()[masked_id]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 543/543 [00:51<00:00, 10.61it/s]\n",
      "  0%|                                                                                          | 0/336 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debiasing by sent_debias...\n",
      "--- get embeddings from AM---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 336/336 [00:12<00:00, 27.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debiasing by sent_debias...\n",
      "For SEAT: effect size is 0.6288013091731618, p value is 0.24934\n",
      "For log probability score: effect size is 1.3634821392803915, p value is 0.00504\n"
     ]
    }
   ],
   "source": [
    "tmp_path = '../data/simple_patterns'\n",
    "\n",
    "corpus, tmps_type, temp_size = convert_tmps_to_sents(tmp_path, eval_type,\\\n",
    "                                                 simple = True)\n",
    "sent2emb = get_embeddings_and_probs_bart(corpus, tmps_type, temp_size, model_type = 'facebook/bart-base'\\\n",
    "                                         , subspace_path = 'bart_saved_embeddings/base_sent/gender_dir_0.07')\n",
    "corpus = add_assos(corpus, tmps_type, temp_size, sent2emb = sent2emb)\n",
    "\n",
    "seat_effect_size, seat_p, log_effect_size, log_p = get_effect_size(corpus)\n",
    "print(\"For SEAT: effect size is {}, p value is {}\".format(seat_effect_size, seat_p))\n",
    "print(\"For log probability score: effect size is {}, p value is {}\".format(log_effect_size, log_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* load gender dir from  bart_saved_embeddings/base_sent/gender_dir_0.07\n",
      "--- 234 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "Testing\n",
      "--- get embeddings from AM---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 234/234 [00:08<00:00, 28.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debiasing by sent_debias...\n",
      "For standard SEAT: effect size is 0.17785143474816928, p value is 0.4503\n"
     ]
    }
   ],
   "source": [
    "if eval_type == 'val':\n",
    "    ori_seat_corpus_path = '../data/val_new_ori_seat_data.json'\n",
    "elif eval_type == 'test':\n",
    "    ori_seat_corpus_path = '../data/test_new_ori_seat_data.json'\n",
    "else:\n",
    "    assert eval_type == 'whole'\n",
    "    ori_seat_corpus_path = '../data/new_ori_seat_data.json'\n",
    "\n",
    "with open(ori_seat_corpus_path, 'r') as f:\n",
    "    test = json.load(f)\n",
    "\n",
    "sent2emb = get_embeddings(test, model_type = 'facebook/bart-base'\\\n",
    "                                         , subspace_path = 'bart_saved_embeddings/base_sent/gender_dir_0.07')\n",
    "\n",
    "seat_ez, p = compute_effect_size(test, sent2emb = sent2emb)\n",
    "\n",
    "print(\"For standard SEAT: effect size is {}, p value is {}\".format(seat_ez, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* load gender dir from  bart_saved_embeddings/base_sent/gender_dir_0.07\n",
      "--- 5220 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "Loading the tokenizer and the model from facebook/bart-base\n",
      "max_len evaluation: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2610/2610 [09:14<00:00,  4.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On UAL_Gender\n",
      "{'error_num': 898, 'error_rate': 0.34406130268199236, 'IA': 0.012022748363724741}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_without_preds_path = '../data/bart_2610_sents_for_evaluating_gender_loss.tsv'\n",
    "\n",
    "data_without_preds = pd.read_csv(data_without_preds_path, sep='\\t', index_col = 0)\n",
    "\n",
    "data = add_predicts_bart(data_without_preds, model_type = \"facebook/bart-base\"\\\n",
    "                                         , subspace_path = 'bart_saved_embeddings/base_sent/gender_dir_0.07')\n",
    "\n",
    "violates, difs = get_vios_and_dif(data)\n",
    "\n",
    "over_debias = {}\n",
    "\n",
    "error_num = len(violates)\n",
    "over_debias['error_num'] = error_num\n",
    "\n",
    "error_rate = len(violates)/len(data)\n",
    "over_debias['error_rate'] = error_rate\n",
    "\n",
    "IA = sum(difs) / len(difs)\n",
    "over_debias['IA'] = IA\n",
    "\n",
    "print(\"On UAL_Gender\")\n",
    "print(over_debias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BART_LARGE_UNCASED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before Debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load tmps from ../data/simple_patterns\n",
      "--- 879 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "Loading tokenizer and model from facebook/bart-large\n",
      "max_len evaluation: 128\n",
      "--- get embeddings from TM and TAM---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 543/543 [00:39<00:00, 13.68it/s]\n",
      "  1%|▍                                                                                 | 2/336 [00:00<00:21, 15.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- get embeddings from AM---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 336/336 [00:21<00:00, 15.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For SEAT: effect size is 1.3774923766961604, p value is 0.00242\n",
      "For log probability score: effect size is 1.6907803901410634, p value is 0.00015\n"
     ]
    }
   ],
   "source": [
    "tmp_path = '../data/simple_patterns'\n",
    "\n",
    "corpus, tmps_type, temp_size = convert_tmps_to_sents(tmp_path, eval_type,\\\n",
    "                                                 simple = True)\n",
    "sent2emb = get_embeddings_and_probs_bart(corpus, tmps_type, temp_size, model_type = 'facebook/bart-large')\n",
    "corpus = add_assos(corpus, tmps_type, temp_size, sent2emb = sent2emb)\n",
    "\n",
    "seat_effect_size, seat_p, log_effect_size, log_p = get_effect_size(corpus)\n",
    "print(\"For SEAT: effect size is {}, p value is {}\".format(seat_effect_size, seat_p))\n",
    "print(\"For log probability score: effect size is {}, p value is {}\".format(log_effect_size, log_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 234 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "Testing\n",
      "--- get embeddings from AM---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 234/234 [00:14<00:00, 15.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For standard SEAT: effect size is 0.5047375119079267, p value is 0.03001\n"
     ]
    }
   ],
   "source": [
    "if eval_type == 'val':\n",
    "    ori_seat_corpus_path = '../data/val_new_ori_seat_data.json'\n",
    "elif eval_type == 'test':\n",
    "    ori_seat_corpus_path = '../data/test_new_ori_seat_data.json'\n",
    "else:\n",
    "    assert eval_type == 'whole'\n",
    "    ori_seat_corpus_path = '../data/new_ori_seat_data.json'\n",
    "\n",
    "with open(ori_seat_corpus_path, 'r') as f:\n",
    "    test = json.load(f)\n",
    "\n",
    "sent2emb = get_embeddings(test, model_type = 'facebook/bart-large')\n",
    "\n",
    "seat_ez, p = compute_effect_size(test, sent2emb = sent2emb)\n",
    "\n",
    "print(\"For standard SEAT: effect size is {}, p value is {}\".format(seat_ez, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5220 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "Loading the tokenizer and the model from facebook/bart-large\n",
      "max_len evaluation: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2610/2610 [06:37<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On UAL_Gender\n",
      "{'error_num': 576, 'error_rate': 0.2206896551724138, 'IA': 1.1096442122755583}\n"
     ]
    }
   ],
   "source": [
    "data_without_preds_path = '../data/bart_2610_sents_for_evaluating_gender_loss.tsv'\n",
    "\n",
    "data_without_preds = pd.read_csv(data_without_preds_path, sep='\\t', index_col = 0)\n",
    "\n",
    "data = add_predicts_bart(data_without_preds, model_type = \"facebook/bart-large\", subspace_path = None)\n",
    "\n",
    "violates, difs = get_vios_and_dif(data)\n",
    "\n",
    "over_debias = {}\n",
    "\n",
    "error_num = len(violates)\n",
    "over_debias['error_num'] = error_num\n",
    "\n",
    "error_rate = len(violates)/len(data)\n",
    "over_debias['error_rate'] = error_rate\n",
    "\n",
    "IA = sum(difs) / len(difs)\n",
    "over_debias['IA'] = IA\n",
    "\n",
    "print(\"On UAL_Gender\")\n",
    "print(over_debias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Sent_debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load tmps from ../data/simple_patterns\n",
      "* load gender dir from  bart_saved_embeddings/large_sent/gender_dir_0.07\n",
      "--- 879 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "Loading tokenizer and model from facebook/bart-large\n",
      "max_len evaluation: 128\n",
      "--- get embeddings from TM and TAM---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 543/543 [01:28<00:00,  6.12it/s]\n",
      "  0%|                                                                                          | 0/336 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debiasing by sent_debias...\n",
      "--- get embeddings from AM---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 336/336 [00:22<00:00, 15.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debiasing by sent_debias...\n",
      "For SEAT: effect size is 1.0492078844511483, p value is 0.03994\n",
      "For log probability score: effect size is 1.2070231944533238, p value is 0.01118\n"
     ]
    }
   ],
   "source": [
    "tmp_path = '../data/simple_patterns'\n",
    "\n",
    "corpus, tmps_type, temp_size = convert_tmps_to_sents(tmp_path, eval_type,\\\n",
    "                                                 simple = True)\n",
    "sent2emb = get_embeddings_and_probs_bart(corpus, tmps_type, temp_size, model_type = 'facebook/bart-large'\\\n",
    "                                         , subspace_path = 'bart_saved_embeddings/large_sent/gender_dir_0.07')\n",
    "corpus = add_assos(corpus, tmps_type, temp_size, sent2emb = sent2emb)\n",
    "\n",
    "seat_effect_size, seat_p, log_effect_size, log_p = get_effect_size(corpus)\n",
    "print(\"For SEAT: effect size is {}, p value is {}\".format(seat_effect_size, seat_p))\n",
    "print(\"For log probability score: effect size is {}, p value is {}\".format(log_effect_size, log_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* load gender dir from  bart_saved_embeddings/large_sent/gender_dir_0.07\n",
      "--- 234 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "Testing\n",
      "--- get embeddings from AM---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 234/234 [00:14<00:00, 15.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debiasing by sent_debias...\n",
      "For standard SEAT: effect size is 0.02694944375827735, p value is 0.90826\n"
     ]
    }
   ],
   "source": [
    "if eval_type == 'val':\n",
    "    ori_seat_corpus_path = '../data/val_new_ori_seat_data.json'\n",
    "elif eval_type == 'test':\n",
    "    ori_seat_corpus_path = '../data/test_new_ori_seat_data.json'\n",
    "else:\n",
    "    assert eval_type == 'whole'\n",
    "    ori_seat_corpus_path = '../data/new_ori_seat_data.json'\n",
    "\n",
    "with open(ori_seat_corpus_path, 'r') as f:\n",
    "    test = json.load(f)\n",
    "\n",
    "sent2emb = get_embeddings(test, model_type = 'facebook/bart-large'\\\n",
    "                                         , subspace_path = 'bart_saved_embeddings/large_sent/gender_dir_0.07')\n",
    "\n",
    "seat_ez, p = compute_effect_size(test, sent2emb = sent2emb)\n",
    "\n",
    "print(\"For standard SEAT: effect size is {}, p value is {}\".format(seat_ez, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* load gender dir from  bart_saved_embeddings/large_sent/gender_dir_0.07\n",
      "--- 5220 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "Loading the tokenizer and the model from facebook/bart-large\n",
      "max_len evaluation: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/2610 [00:00<?, ?it/s]C:\\Hello_Mulin\\My_study-base\\experiments\\phase2\\Unimelb_fairness_project_phase2\\bart\\initial_evaluation\\intial_eval_utils\\evaluating_over_debiasing_bart.py:53: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:882.)\n",
      "  TM_mask_pos = (TM_input_b[b] == tokenizer.mask_token_id).nonzero().flatten().tolist()[0]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2610/2610 [14:35<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On UAL_Gender\n",
      "{'error_num': 991, 'error_rate': 0.3796934865900383, 'IA': 0.012623119032456973}\n"
     ]
    }
   ],
   "source": [
    "data_without_preds_path = '../data/bart_2610_sents_for_evaluating_gender_loss.tsv'\n",
    "\n",
    "data_without_preds = pd.read_csv(data_without_preds_path, sep='\\t', index_col = 0)\n",
    "\n",
    "data = add_predicts_bart(data_without_preds, model_type = \"facebook/bart-large\"\\\n",
    "                                         , subspace_path = 'bart_saved_embeddings/large_sent/gender_dir_0.07')\n",
    "\n",
    "violates, difs = get_vios_and_dif(data)\n",
    "\n",
    "over_debias = {}\n",
    "\n",
    "error_num = len(violates)\n",
    "over_debias['error_num'] = error_num\n",
    "\n",
    "error_rate = len(violates)/len(data)\n",
    "over_debias['error_rate'] = error_rate\n",
    "\n",
    "IA = sum(difs) / len(difs)\n",
    "over_debias['IA'] = IA\n",
    "\n",
    "print(\"On UAL_Gender\")\n",
    "print(over_debias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
