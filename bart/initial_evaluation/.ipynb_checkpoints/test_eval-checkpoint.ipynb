{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intial_eval_utils.evaluating_debiasing_effects_by_diverse import convert_tmps_to_sents, get_embeddings_and_probs, add_assos\n",
    "from intial_eval_utils.ori_seat import get_embeddings, compute_effect_size\n",
    "\n",
    "from intial_eval_utils.bias_utils.debiasing_effects_util import get_effect_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_type = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-05 20:13:39,081 : INFO : The debiasing effects evaluation type is whole\n",
      "2021-09-05 20:13:39,115 : INFO : * The model type is bert-base-uncased\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load tmps from ../data/simple_patterns\n",
      "--- 1083 sentens to be processes ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-05 20:13:41,368 : INFO : ****** The model is bert-base-uncased\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2021-09-05 20:13:45,956 : INFO : ******1 The type of used model is <class 'transformers.models.bert.modeling_bert.BertForMaskedLM'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- get embeddings from TM and TAM---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/663 [00:00<?, ?it/s]../evaluation_for_trade_off\\bias_utils\\utils_for_diverse_tmps.py:297: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  ..\\torch\\csrc\\utils\\python_arg_parser.cpp:882.)\n",
      "  mask_index = (sents[sent_id] == tokenizer.mask_token_id).nonzero().flatten().tolist()[masked_id]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 663/663 [00:23<00:00, 28.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- get embeddings from AM---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 420/420 [00:12<00:00, 34.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.896259110855652\n",
      "1.9474210595181205\n"
     ]
    }
   ],
   "source": [
    "tmp_path = '../data/simple_patterns'\n",
    "\n",
    "corpus, tmps_type, temp_size = convert_tmps_to_sents(tmp_path, eval_type,\n",
    "                                                 simple = True)\n",
    "sent2emb, model_type = get_embeddings_and_probs(corpus, tmps_type, temp_size, model_type = 'bert-base-uncased')\n",
    "corpus = add_assos(corpus, tmps_type, temp_size, model_type = 'bert-base-uncased', sent2emb = sent2emb)\n",
    "\n",
    "seat_effect_size, log_effect_size = get_effect_size(corpus)\n",
    "print(seat_effect_size)\n",
    "print(log_effect_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-05 20:03:18,137 : INFO : The debiasing effects evaluation type is val\n",
      "2021-09-05 20:03:18,144 : INFO : * The model type is bert-base-uncased\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load tmps from ../data/simple_patterns\n",
      "--- 105 sentens to be processes ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-05 20:03:19,339 : INFO : ****** The model is bert-base-uncased\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2021-09-05 20:03:24,317 : INFO : ******1 The type of used model is <class 'transformers.models.bert.modeling_bert.BertForMaskedLM'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- get embeddings from TM and TAM---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:01<00:00, 27.94it/s]\n",
      "  8%|██████▍                                                                            | 4/52 [00:00<00:01, 35.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- get embeddings from AM---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 35.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9521019931965795\n",
      "1.994748449911582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_type = 'val'\n",
    "tmp_path = '../data/simple_patterns'\n",
    "\n",
    "corpus, tmps_type, temp_size = convert_tmps_to_sents(tmp_path, eval_type,\n",
    "                                                 simple = True)\n",
    "sent2emb, model_type = get_embeddings_and_probs(corpus, tmps_type, temp_size, model_type = 'bert-base-uncased')\n",
    "corpus = add_assos(corpus, tmps_type, temp_size, model_type = 'bert-base-uncased', sent2emb = sent2emb)\n",
    "\n",
    "seat_effect_size, log_effect_size = get_effect_size(corpus)\n",
    "print(seat_effect_size)\n",
    "print(log_effect_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-05 20:03:28,211 : INFO : The debiasing effects evaluation type is test\n",
      "2021-09-05 20:03:28,234 : INFO : * The model type is bert-base-uncased\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load tmps from ../data/simple_patterns\n",
      "--- 879 sentens to be processes ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-05 20:03:29,398 : INFO : ****** The model is bert-base-uncased\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "2021-09-05 20:03:34,466 : INFO : ******1 The type of used model is <class 'transformers.models.bert.modeling_bert.BertForMaskedLM'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- get embeddings from TM and TAM---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 543/543 [00:18<00:00, 28.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- get embeddings from AM---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 336/336 [00:09<00:00, 33.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9427828883830491\n",
      "1.966382127046125\n"
     ]
    }
   ],
   "source": [
    "eval_type = 'test'\n",
    "tmp_path = '../data/simple_patterns'\n",
    "\n",
    "corpus, tmps_type, temp_size = convert_tmps_to_sents(tmp_path, eval_type,\n",
    "                                                 simple = True)\n",
    "sent2emb, model_type = get_embeddings_and_probs(corpus, tmps_type, temp_size, model_type = 'bert-base-uncased')\n",
    "corpus = add_assos(corpus, tmps_type, temp_size, model_type = 'bert-base-uncased', sent2emb = sent2emb)\n",
    "\n",
    "seat_effect_size, log_effect_size = get_effect_size(corpus)\n",
    "print(seat_effect_size)\n",
    "print(log_effect_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 294 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "load model from bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len evaluation: 128\n",
      "--- get embeddings from AM---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 294/294 [00:08<00:00, 34.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.59117221561243, 0.0)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "eval_type = 'whole'\n",
    "\n",
    "if eval_type == 'val':\n",
    "    ori_seat_corpus_path = '../data/val_new_ori_seat_data.json'\n",
    "elif eval_type == 'test':\n",
    "    ori_seat_corpus_path = '../data/test_new_ori_seat_data.json'\n",
    "else:\n",
    "    assert eval_type == 'whole'\n",
    "    ori_seat_corpus_path = '../data/new_ori_seat_data.json'\n",
    "\n",
    "with open(ori_seat_corpus_path, 'r') as f:\n",
    "    test = json.load(f)\n",
    "\n",
    "sent2emb = get_embeddings(test, model_type = 'bert-base-uncased')\n",
    "\n",
    "seat_ez, p = compute_effect_size(test, sent2emb = sent2emb)\n",
    "\n",
    "print((seat_ez, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 60 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "load model from bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len evaluation: 128\n",
      "--- get embeddings from AM---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:01<00:00, 33.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.3558057513345059, 0.0011)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "eval_type = 'val'\n",
    "\n",
    "if eval_type == 'val':\n",
    "    ori_seat_corpus_path = '../data/val_new_ori_seat_data.json'\n",
    "elif eval_type == 'test':\n",
    "    ori_seat_corpus_path = '../data/test_new_ori_seat_data.json'\n",
    "else:\n",
    "    assert eval_type == 'whole'\n",
    "    ori_seat_corpus_path = '../data/new_ori_seat_data.json'\n",
    "\n",
    "with open(ori_seat_corpus_path, 'r') as f:\n",
    "    test = json.load(f)\n",
    "\n",
    "sent2emb = get_embeddings(test, model_type = 'bert-base-uncased')\n",
    "\n",
    "seat_ez, p = compute_effect_size(test, sent2emb = sent2emb)\n",
    "\n",
    "print((seat_ez, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 234 sentens to be processes ---\n",
      "We will use the GPU: GeForce GTX 1650\n",
      "load model from bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len evaluation: 128\n",
      "--- get embeddings from AM---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 234/234 [00:06<00:00, 34.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.7004990198053145, 0.0)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "eval_type = 'test'\n",
    "\n",
    "if eval_type == 'val':\n",
    "    ori_seat_corpus_path = '../data/val_new_ori_seat_data.json'\n",
    "elif eval_type == 'test':\n",
    "    ori_seat_corpus_path = '../data/test_new_ori_seat_data.json'\n",
    "else:\n",
    "    assert eval_type == 'whole'\n",
    "    ori_seat_corpus_path = '../data/new_ori_seat_data.json'\n",
    "\n",
    "with open(ori_seat_corpus_path, 'r') as f:\n",
    "    test = json.load(f)\n",
    "\n",
    "sent2emb = get_embeddings(test, model_type = 'bert-base-uncased')\n",
    "\n",
    "seat_ez, p = compute_effect_size(test, sent2emb = sent2emb)\n",
    "\n",
    "print((seat_ez, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
